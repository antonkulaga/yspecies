{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load expressions\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from yspecies import *\n",
    "from yspecies.enums import *\n",
    "from yspecies.dataset import *\n",
    "from yspecies.misc import *\n",
    "from yspecies.workflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters cell ##\n",
    "\n",
    "Parameters are overiddent by papermill when run inside DVC stages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_bootstraps = 5 # this sets global setting of which how many bootstraps to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "locations: Locations = Locations(\"./\") if Path(\"./data\").exists() else Locations(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='2'><caption>selected<caption><tr><th>expressions</th><th>genes</th><th>species</th><th>samples</th><th>Genes Metadata</th><th>Species Metadata</th></tr><tr><td>(445, 12243)</td><td>12243</td><td>39</td><td>445</td><td>None</td><td>None</td></tr></table>"
      ],
      "text/plain": [
       "<yspecies.dataset.ExpressionDataset at 0x7f03468ff150>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ExpressionDataset.from_folder(locations.interim.selected)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save label encoders to global scope\n",
    "le_tissue = LabelEncoder()\n",
    "le_order = LabelEncoder()\n",
    "enc_tissue = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_order = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_lightgbm(X_train, X_test, y_train, y_test, categorical):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    evals_result = {}\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'max_leaves': 20,\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.07,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 1,\n",
    "        'min_data_in_leaf': 6,\n",
    "        'lambda_l1': 0.9,\n",
    "        'lambda_l2': 0.9,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "        lgb_train,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=lgb_eval,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        early_stopping_rounds=7)\n",
    "    \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_stratification(X, Y, k, species_validation=True):\n",
    "    X['target'] = Y\n",
    "    X = X.sort_values(by=['target'])\n",
    "    \n",
    "    if species_validation:\n",
    "        all_species = list(set(X[X['common_name']!= 'Human']['common_name'].values))\n",
    "        df_index = X.index\n",
    "\n",
    "        k_sets_indexes = []\n",
    "        k_sets_of_species_names = []\n",
    "        already_selected = []\n",
    "        for i in range(k):\n",
    "            index_set = []\n",
    "            choice1 = random.choice(all_species)\n",
    "            while (choice1 in already_selected):\n",
    "                choice1 = random.choice(all_species)\n",
    "            already_selected.append(choice1)\n",
    "\n",
    "            choice2 = random.choice(all_species)\n",
    "            while (choice2 in already_selected):\n",
    "                choice2 = random.choice(all_species)\n",
    "            already_selected.append(choice2)\n",
    "\n",
    "            k_sets_of_species_names.append([choice1, choice2])\n",
    "            common_names = X['common_name'].values\n",
    "            for j, c in enumerate(common_names):\n",
    "                if c == choice1 or c == choice2:\n",
    "                    index_set.append(j)\n",
    "            k_sets_indexes.append(index_set)\n",
    "        \n",
    "    \n",
    "    partition_indexes = [[] for i in range(k)]\n",
    "    i = 0\n",
    "    index_of_sample = 0\n",
    "   \n",
    "    while i < (int(len(Y)/k)): \n",
    "        for j in range(k):\n",
    "            partition_indexes[j].append((i*k)+j)\n",
    "            index_of_sample = (i*k)+j\n",
    "        i+=1\n",
    "\n",
    "    index_of_sample += 1\n",
    "    i = 0\n",
    "    while index_of_sample < len(Y):\n",
    "        partition_indexes[i].append(index_of_sample)\n",
    "        index_of_sample += 1\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    X_features = X.drop(['target', 'common_name'], axis=1)\n",
    "    Y = X['target'].values\n",
    "    common_names_df = X['common_name'].values\n",
    "    X = X.drop(['target', 'common_name'], axis=1) \n",
    "    \n",
    "    if species_validation:\n",
    "        print('Species for validation', k_sets_of_species_names)\n",
    "        \n",
    "    partition_Xs = []\n",
    "    partition_Ys = []\n",
    "    common_name_partitions = []\n",
    "    \n",
    "    if species_validation:\n",
    "        for i, pindex in enumerate(partition_indexes):\n",
    "            for j, sindex in enumerate(k_sets_indexes):\n",
    "                if i == j:\n",
    "                    partition_indexes[i] = list(set(partition_indexes[i]).union(set(k_sets_indexes[j])))\n",
    "                else:\n",
    "                    partition_indexes[i] = list(set(partition_indexes[i]).difference(set(k_sets_indexes[j])))\n",
    "            \n",
    "        \n",
    "    for i, pindex in enumerate(partition_indexes):\n",
    "        partition_Xs.append(X_features.iloc[pindex])\n",
    "        common_name_partitions.append(common_names_df[pindex])\n",
    "        partition_Ys.append(Y[pindex])\n",
    "        \n",
    "       \n",
    "    return X, Y, partition_Xs, partition_Ys, common_name_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(prediction, ground_truth):\n",
    "     return {\n",
    "            'R2': r2_score(ground_truth, prediction),\n",
    "            'MSE': mean_squared_error(ground_truth, prediction),\n",
    "            'MAE': mean_absolute_error(ground_truth, prediction),\n",
    "     }\n",
    "    \n",
    "def encode_tissues(dataframe):\n",
    "    le.fit(dataframe['tissue'].values)\n",
    "    tissues_encoded = le.transform(dataframe['tissue'].values)\n",
    "    dataframe['tissue_encoded'] = tissues_encoded\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "def split_to_X_and_Y(dataframe, label_to_predict):\n",
    "    if 'tissue' in dataframe.columns:\n",
    "        X = dataframe.drop([label_to_predict, 'tissue'], axis=1)\n",
    "        Y = dataframe[label_to_predict].values\n",
    "        index_of_categorical_feature = list(X.columns).index('tissue_encoded')\n",
    "    else:\n",
    "        X = dataframe.drop([label_to_predict], axis=1)\n",
    "        Y = dataframe[label_to_predict].values\n",
    "        index_of_categorical_feature = None\n",
    "\n",
    "    return X, X.values, Y, index_of_categorical_feature\n",
    "    \n",
    "    \n",
    "def get_predictions(label_to_predict, ids=None):\n",
    "    species_data = pd.read_csv('cross_species_df_merged.csv', low_memory=False)\n",
    "    \n",
    "    # remove other features (redundant and those that correlate with target)\n",
    "    cols_to_delete = []\n",
    "    for column in list(species_data.columns):\n",
    "        if ids:\n",
    "            if column not in ids and column not in ['tissue', label_to_predict]:\n",
    "                cols_to_delete.append(column)\n",
    "        else:\n",
    "            if 'ENSG' not in column and column not in ['tissue', label_to_predict]:\n",
    "                cols_to_delete.append(column)    \n",
    "            \n",
    "    species_data = species_data.drop(cols_to_delete, axis=1) \n",
    "    \n",
    "    species_data = species_data[(~pd.isnull(species_data[label_to_predict]))] # select only row where target is set\n",
    "    species_data = species_data.dropna(axis=1, thresh=int(len(species_data)*0.9)) # remove all genes where percentage of NaN > 10%\n",
    "    species_data = species_data[species_data['tissue'].isin(['Lung', 'Liver', 'Kidney', 'Brain', 'Heart'])] # remove underrepresented tissues\n",
    "    species_data = encode_tissues(species_data)\n",
    "    \n",
    "    print('Number of samples', len(species_data))\n",
    "    print('Number of genes', len(species_data.columns))\n",
    "    \n",
    "    feature_df, X, Y, index_of_categorical = split_to_X_and_Y(species_data, label_to_predict)\n",
    "    \n",
    "    object_from_training = calculate_stable_shap_values(feature_df, Y, index_of_categorical, label_to_predict)\n",
    "    features_weighted = object_from_training['list_of_weighted_features']\n",
    "    shap_values = object_from_training['stable_shap_values']\n",
    "    \n",
    "    return shap_values, feature_df, features_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of selected genes for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File cross_species_df_merged.csv does not exist: 'cross_species_df_merged.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2a62e58c67d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gestation_days'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_lifespan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mass_g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'temperature_celsius'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metabolic_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mtGC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlifespan_weighted_features\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweighted_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlifespan_shap_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-6a3c5b683189>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(label_to_predict, ids)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_to_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mspecies_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cross_species_df_merged.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# remove other features (redundant and those that correlate with target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File cross_species_df_merged.csv does not exist: 'cross_species_df_merged.csv'"
     ]
    }
   ],
   "source": [
    "lifespan_weighted_features = []\n",
    "lifespan_shap_values = []\n",
    "lifespan_dataframes = []\n",
    "\n",
    "for label in ['gestation_days', 'max_lifespan', 'mass_g', 'temperature_celsius', 'metabolic_rate', 'mtGC']:\n",
    "    shap_values, feature_df, weighted_features = get_predictions(label)\n",
    "    lifespan_weighted_features += weighted_features\n",
    "    lifespan_shap_values.append(shap_values)\n",
    "    lifespan_dataframes.append(feature_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
