{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load expressions\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from yspecies import *\n",
    "from yspecies.enums import *\n",
    "from yspecies.dataset import *\n",
    "from yspecies.misc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters cell ##\n",
    "\n",
    "Parameters are overiddent by papermill when run inside DVC stages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_BOOTSTRAPS = 5 # this sets global setting of which how many bootstraps to use\n",
    "TISSUES_LIST = ['Lung', 'Liver', 'Kidney', 'Brain', 'Heart'] # this sets global setting of which tissue to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save label encoders to global scope\n",
    "le_tissue = LabelEncoder()\n",
    "le_order = LabelEncoder()\n",
    "enc_tissue = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_order = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model_lightgbm(X_train, X_test, y_train, y_test, categorical):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    evals_result = {}\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'max_leaves': 20,\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.07,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 1,\n",
    "        'min_data_in_leaf': 6,\n",
    "        'lambda_l1': 0.9,\n",
    "        'lambda_l2': 0.9,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "        lgb_train,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=lgb_eval,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=1000,\n",
    "        early_stopping_rounds=7)\n",
    "    \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_stratification(X, Y, k, species_validation=True):\n",
    "    X['target'] = Y\n",
    "    X = X.sort_values(by=['target'])\n",
    "    \n",
    "    if species_validation:\n",
    "        all_species = list(set(X[X['common_name']!= 'Human']['common_name'].values))\n",
    "        df_index = X.index\n",
    "\n",
    "        k_sets_indexes = []\n",
    "        k_sets_of_species_names = []\n",
    "        already_selected = []\n",
    "        for i in range(k):\n",
    "            index_set = []\n",
    "            choice1 = random.choice(all_species)\n",
    "            while (choice1 in already_selected):\n",
    "                choice1 = random.choice(all_species)\n",
    "            already_selected.append(choice1)\n",
    "\n",
    "            choice2 = random.choice(all_species)\n",
    "            while (choice2 in already_selected):\n",
    "                choice2 = random.choice(all_species)\n",
    "            already_selected.append(choice2)\n",
    "\n",
    "            k_sets_of_species_names.append([choice1, choice2])\n",
    "            common_names = X['common_name'].values\n",
    "            for j, c in enumerate(common_names):\n",
    "                if c == choice1 or c == choice2:\n",
    "                    index_set.append(j)\n",
    "            k_sets_indexes.append(index_set)\n",
    "        \n",
    "    \n",
    "    partition_indexes = [[] for i in range(k)]\n",
    "    i = 0\n",
    "    index_of_sample = 0\n",
    "   \n",
    "    while i < (int(len(Y)/k)): \n",
    "        for j in range(k):\n",
    "            partition_indexes[j].append((i*k)+j)\n",
    "            index_of_sample = (i*k)+j\n",
    "        i+=1\n",
    "\n",
    "    index_of_sample += 1\n",
    "    i = 0\n",
    "    while index_of_sample < len(Y):\n",
    "        partition_indexes[i].append(index_of_sample)\n",
    "        index_of_sample += 1\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    X_features = X.drop(['target', 'common_name'], axis=1)\n",
    "    Y = X['target'].values\n",
    "    common_names_df = X['common_name'].values\n",
    "    X = X.drop(['target', 'common_name'], axis=1) \n",
    "    \n",
    "    if species_validation:\n",
    "        print('Species for validation', k_sets_of_species_names)\n",
    "        \n",
    "    partition_Xs = []\n",
    "    partition_Ys = []\n",
    "    common_name_partitions = []\n",
    "    \n",
    "    if species_validation:\n",
    "        for i, pindex in enumerate(partition_indexes):\n",
    "            for j, sindex in enumerate(k_sets_indexes):\n",
    "                if i == j:\n",
    "                    partition_indexes[i] = list(set(partition_indexes[i]).union(set(k_sets_indexes[j])))\n",
    "                else:\n",
    "                    partition_indexes[i] = list(set(partition_indexes[i]).difference(set(k_sets_indexes[j])))\n",
    "            \n",
    "        \n",
    "    for i, pindex in enumerate(partition_indexes):\n",
    "        partition_Xs.append(X_features.iloc[pindex])\n",
    "        common_name_partitions.append(common_names_df[pindex])\n",
    "        partition_Ys.append(Y[pindex])\n",
    "        \n",
    "       \n",
    "    return X, Y, partition_Xs, partition_Ys, common_name_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets():\n",
    "    expressions = pd.read_csv('./../data/interim/selected_expressions.tsv', sep='\\t')\n",
    "    samples = pd.read_csv('./../data/interim/selected_samples.tsv', sep=\"\\t\", index_col=None, dtype=None)\n",
    "    bad_samples = [\n",
    "        \"SRR8750397\", #may be single-cell\n",
    "        \"SRR8750398\", #may be single-cell\n",
    "        \"SRR8750399\", #may be single-cell\n",
    "        \"SRR3109726\", #old kidney\n",
    "        \"SRR3109728\", #old kidney\n",
    "        \"SRR3403827\", #brainsteam\n",
    "        \"SRR3403828\", #brainsteam\n",
    "        \"SRR306404\", #hypoxia exposed\n",
    "        \"SRR306406\"\n",
    "    ]\n",
    "    samples = samples[~samples['run'].isin(bad_samples)]\n",
    "    samples = samples.set_index('run')\n",
    "    expressions = expressions.set_index('run')\n",
    "    cross_species_joined_df = expressions.merge(samples, left_on='run', right_on='run')\n",
    "     \n",
    "    print('Number of samples', len(cross_species_joined_df))\n",
    "    cross_species_joined_df.to_csv('cross_species_df_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pathes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sources/species/notebooks/..\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if(Path(\"./data\").exists()):\n",
    "    base_dir = Path(\"./\")\n",
    "else:\n",
    "    base_dir = Path(\"../\")\n",
    "print(base_dir.absolute())\n",
    "\n",
    "data_dir = base_dir / \"data\"\n",
    "input_dir = data_dir / \"input\"\n",
    "interim_dir = data_dir / \"interim\"\n",
    "output_dir =  data_dir / \"output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(path: Path, index: str = None, dtype: str = None)->pd.DataFrame:    \n",
    "    if index is None:\n",
    "        return pd.read_csv(str(path), sep=\"\\t\", dtype=dtype)\n",
    "    else:\n",
    "        return pd.read_csv(str(path), sep=\"\\t\", index_col=index, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(df: pd.DataFrame, cols: int, rows: int = 3) -> pd.DataFrame:\n",
    "    return df[df.columns[0:cols]].head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/interim/selected_genes.tsv does not exist: '../data/interim/selected_genes.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-72604aa9b6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterim_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"selected_genes.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Homo_sapiens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterim_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"selected_samples.tsv\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspecies\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterim_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"selected_species.tsv\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"species\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexpressions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterim_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"selected_expressions.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m tab(\n",
      "\u001b[0;32m<ipython-input-11-39068e59d36f>\u001b[0m in \u001b[0;36mload_table\u001b[0;34m(path, index, dtype)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/species/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/interim/selected_genes.tsv does not exist: '../data/interim/selected_genes.tsv'"
     ]
    }
   ],
   "source": [
    "genes = load_table(interim_dir / \"selected_genes.tsv\", index=\"Homo_sapiens\")  \n",
    "samples =  load_table(interim_dir / \"selected_samples.tsv\" , index=\"run\").sort_index() \n",
    "species =  load_table(interim_dir / \"selected_species.tsv\" , index=\"species\")\n",
    "expressions = load_table(interim_dir / \"selected_expressions.tsv\", index=\"run\").sort_index()\n",
    "tab(\n",
    "[\n",
    "    [\"genes\", \"samples\", \"species\", \"expressions\"],\n",
    "    [genes.shape, samples.shape, species.shape, expressions.shape]\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expressions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-67a03690d6ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'expressions' is not defined"
     ]
    }
   ],
   "source": [
    "expressions.columns == genes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<yspecies.dataset.Dataset at 0x7ff212188dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dataset(\"selected_species\", expressions, genes, samples)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53fbaa6b4f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples_colnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d.get_samples_colnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
