{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP feature selection #\n",
    "## Code to select feature with combination of LightGBM and SHAP ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters cell ##\n",
    "\n",
    "Parameters are overiddent by papermill when run inside DVC stages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "number_of_folds = 5 # this sets global setting of which how many bootstraps to use\n",
    "repeats = 15\n",
    "#first round of optimization\n",
    "lgb_params = {\n",
    " \"objective\": \"regression\",\n",
    " 'boosting_type': 'gbdt', \n",
    " 'metric': ['mae','mse', 'huber'],\n",
    " 'lambda_l1': 0.03674546022666247, \n",
    " 'lambda_l2': 2.5025758383109715, \n",
    " 'max_leaves': 22,\n",
    " 'max_depth': 6, \n",
    " 'feature_fraction': 0.741996402547356, \n",
    " 'bagging_fraction': 0.8929839112500518, \n",
    " 'learning_rate': 0.0892243160116563, \n",
    " 'min_data_in_leaf': 5, \n",
    " 'drop_rate': 0.14842616274718734    \n",
    "}\n",
    "\n",
    "debug_local = True #to use local version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extending pathes with local yspecies\n",
      "['..', '..', '..', '..', '..', '/data/sources/yspecies/notebooks', '/opt/miniconda3/envs/yspecies/lib/python38.zip', '/opt/miniconda3/envs/yspecies/lib/python3.8', '/opt/miniconda3/envs/yspecies/lib/python3.8/lib-dynload', '', '/opt/miniconda3/envs/yspecies/lib/python3.8/site-packages', '/opt/miniconda3/envs/yspecies/lib/python3.8/site-packages/IPython/extensions', '/home/antonkulaga/.ipython']\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "local = (Path(\"..\") / \"yspecies\").resolve()\n",
    "if debug_local and local.exists():\n",
    "  sys.path.insert(0, Path(\"..\").as_posix())\n",
    "  #sys.path.insert(0, local.as_posix())\n",
    "  print(\"extending pathes with local yspecies\")\n",
    "  print(sys.path)\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from yspecies.dataset import *\n",
    "from yspecies.utils import *\n",
    "from yspecies.workflow import TupleWith, Repeat\n",
    "from yspecies.config import *\n",
    "from yspecies.preprocess import FeatureSelection, DataExtractor\n",
    "from yspecies.partition import DataPartitioner, PartitionParameters\n",
    "from yspecies.models import Metrics\n",
    "from yspecies.selection import ShapSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "#charts settings\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib auto\n",
    "plt.ioff()\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data ###\n",
    "Let's load data from species/genes/expressions selected by select_samples.py notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "locations: Locations = Locations(\"./\") if Path(\"./data\").exists() else Locations(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='2'><caption>selected<caption><tr><th>expressions</th><th>genes</th><th>species</th><th>samples</th><th>Genes Metadata</th><th>Species Metadata</th></tr><tr><td>(445, 12340)</td><td>12340</td><td>39</td><td>445</td><td>(12340, 2)</td><td>(40, 19)</td></tr></table>"
      ],
      "text/plain": [
       "<yspecies.dataset.ExpressionDataset at 0x7ff94c0489d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ExpressionDataset.from_folder(locations.interim.selected)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up SHAP selection pipeline ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding on selection parameters (which fields to include, exclude, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_params = PartitionParameters(number_of_folds, 0, 2, [],  42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_shap_pipe = Pipeline([\n",
    "    (\"partitioner\", DataPartitioner()),\n",
    "    ('prepare_for_partitioning', TupleWith(lgb_params)),\n",
    "    (\"shap_computation\", ShapSelector())\n",
    "]\n",
    ")\n",
    "repeated_cv =  Repeat(partition_shap_pipe, repeats, lambda x,i: (x[0], replace(x[1], seed = i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_pipeline =  Pipeline([\n",
    "    ('extractor', DataExtractor()),\n",
    "    ('prepare_for_partitioning', TupleWith(partition_params)), # to extract the data required for ML from the dataset\n",
    "    (\"partition_shap\", repeated_cv)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up features to select ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = select_lifespan = FeatureSelection(\n",
    "    samples = [\"tissue\",\"species\"], #samples metadata to include\n",
    "    species =  [], #species metadata other then Y label to include\n",
    "    exclude_from_training = [\"species\"],  #exclude some fields from LightGBM training\n",
    "    to_predict = \"lifespan\", #column to predict\n",
    "    categorical = [\"tissue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lifespan = selection\n",
    "select_mass = replace(selection, to_predict = \"mass_g\")\n",
    "select_gestation = replace(selection, to_predict = \"gestation\")\n",
    "select_mtgc = replace(selection, to_predict = \"mtgc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First stage selection #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's l1: 10.7666\tvalid_0's l2: 242.451\tvalid_0's huber: 9.28714\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's l1: 2.33282\tvalid_0's l2: 17.7251\tvalid_0's huber: 1.83076\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's l1: 3.66061\tvalid_0's l2: 56.0589\tvalid_0's huber: 2.99792\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's l1: 7.33974\tvalid_0's l2: 144.605\tvalid_0's huber: 6.27978\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l1: 3.11934\tvalid_0's l2: 22.2578\tvalid_0's huber: 2.48032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n",
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n",
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n",
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 4.21986\tvalid_0's l2: 81.8091\tvalid_0's huber: 3.48915\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's l1: 5.82709\tvalid_0's l2: 58.1638\tvalid_0's huber: 4.8496\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's l1: 21.6611\tvalid_0's l2: 1885.6\tvalid_0's huber: 19.1666\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l1: 8.21728\tvalid_0's l2: 181.643\tvalid_0's huber: 7.06653\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    }
   ],
   "source": [
    "stage_one_lifespan = selection_pipeline.fit_transform((data, select_lifespan))\n",
    "stage_one_lifespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yspecies.results import FeatureSummary\n",
    "summary = FeatureSummary(stage_one_lifespan)\n",
    "stage_one_lifespan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.selected.sort_values(\"kendall_tau_0\", ascending=False)[\"symbol\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gain'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"gain\" if len([c for c in summary.results[0].selected.columns if \"gain\" in c])>0 else \"shap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
