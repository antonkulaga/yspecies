{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters optimization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters cell ##\n",
    "\n",
    "Parameters are overiddent by papermill when run inside DVC stages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "number_of_folds = 5 # this sets global setting of which how many bootstraps to use\n",
    "repeats = 10\n",
    "n_trials = 50\n",
    "#first round of optimization\n",
    "lgb_params = {\"bagging_fraction\": 0.9522534844058304, \n",
    "              \"boosting_type\": \"dart\", \n",
    "              \"objective\": \"regression\",\n",
    "              \"feature_fraction\": 0.42236910941558053, \n",
    "              \"lambda_l1\": 0.020847266580277746, \n",
    "              \"lambda_l2\": 2.8448564854773326, \n",
    "              \"learning_rate\": 0.11484015430016059, \n",
    "              \"max_depth\": 3, \n",
    "              \"max_leaves\": 35, \n",
    "              \"min_data_in_leaf\": 9,\n",
    "              \"num_iterations\": 150\n",
    "             }\n",
    "debug_local = True #to use local version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "local = (Path(\"..\") / \"yspecies\").resolve()\n",
    "if debug_local and local.exists():\n",
    "  sys.path.insert(0, Path(\"..\").as_posix())\n",
    "  #sys.path.insert(0, local.as_posix())\n",
    "  print(\"extending pathes with local yspecies\")\n",
    "  print(sys.path)\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from yspecies.dataset import *\n",
    "from yspecies.utils import *\n",
    "from yspecies.workflow import TupleWith, Repeat, Collect\n",
    "from yspecies.config import *\n",
    "from yspecies.preprocess import FeatureSelection, DataExtractor\n",
    "from yspecies.partition import DataPartitioner, PartitionParameters\n",
    "from yspecies.selection import ShapSelector\n",
    "from yspecies.tuning import Tune\n",
    "from yspecies.models import ResultsCV, CrossValidator\n",
    "import optuna\n",
    "from optuna import Study, Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "#charts settings\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib auto\n",
    "plt.ioff()\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data ###\n",
    "Let's load data from species/genes/expressions selected by select_samples.py notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "locations: Locations = Locations(\"./\") if Path(\"./data\").exists() else Locations(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='2'><caption>selected<caption><tr><th>expressions</th><th>genes</th><th>species</th><th>samples</th><th>Genes Metadata</th><th>Species Metadata</th></tr><tr><td>(445, 12340)</td><td>12340</td><td>39</td><td>445</td><td>(12340, 2)</td><td>(40, 19)</td></tr></table>"
      ],
      "text/plain": [
       "<yspecies.dataset.ExpressionDataset at 0x7f5ccc7d8790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ExpressionDataset.from_folder(locations.interim.selected)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that crossvalidation works ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding on selection parameters (which fields to include, exclude, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_params = PartitionParameters(number_of_folds, 1, 2, [],  42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_cv_pipe = Pipeline([\n",
    "    ('partitioner', DataPartitioner()),\n",
    "    ('prepare_for_partitioning', TupleWith(lgb_params)),\n",
    "    ('crossvalidator', CrossValidator())\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_cv_pipe =  Repeat(partition_cv_pipe, repeats, lambda x,i: (x[0], replace(x[1], seed = i)))\n",
    "cv_pipeline =  Pipeline([\n",
    "    ('extractor', DataExtractor()),\n",
    "    ('prepare_for_partitioning', TupleWith(partition_params)), # to extract the data required for ML from the dataset\n",
    "    (\"partition_cv\", repeated_cv_pipe)\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up features to select ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = select_lifespan = FeatureSelection(\n",
    "    samples = [\"tissue\",\"species\"], #samples metadata to include\n",
    "    species =  [], #species metadata other then Y label to include\n",
    "    exclude_from_training = [\"species\"],  #exclude some fields from LightGBM training\n",
    "    to_predict = \"lifespan\", #column to predict\n",
    "    categorical = [\"tissue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lifespan = selection\n",
    "select_mass = replace(selection, to_predict = \"mass_g\")\n",
    "select_gestation = replace(selection, to_predict = \"gestation\")\n",
    "select_mtgc = replace(selection, to_predict = \"mtgc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking cross-validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_iterations` in params. Will use it instead of argument\n",
      "Early stopping is not available in dart mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tcv_agg's l1: 7.43114 + 6.21527\tcv_agg's l2: 100.42 + 105.483\tcv_agg's huber: 6.32338 + 5.55987\n",
      "[150]\tcv_agg's l1: 2.40938 + 0.220618\tcv_agg's l2: 33.1796 + 2.89302\tcv_agg's huber: 1.83441 + 0.192833\n",
      "[150]\tcv_agg's l1: 2.35449 + 0.17208\tcv_agg's l2: 32.8908 + 4.3389\tcv_agg's huber: 1.79183 + 0.140331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3668827684898497"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = cv_pipeline.fit_transform((data, select_lifespan))\n",
    "ResultsCV.take_best(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[6.323384741941977, 1.83440742061015, 1.7918279322321973]"
      ],
      "text/plain": [
       "[6.323384741941977, 1.83440742061015, 1.7918279322321973]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c.last(\"huber\")for c in cv_res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading (if exists) study from sqlite:////data/sources/yspecies/notebooks/../data/metrics/lifespan/study.sqlite\n"
     ]
    }
   ],
   "source": [
    "url = f'sqlite:///' +str((locations.metrics.lifespan / \"study.sqlite\").absolute())\n",
    "print('loading (if exists) study from '+url)\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=url\n",
    "    #engine_kwargs={'check_same_thread': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_parameters(trial: Trial) -> dict:\n",
    "    return {\n",
    "        'objective': 'regression',\n",
    "        'metric': {'mae', 'mse', 'huber'},\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['dart', 'gbdt']),\n",
    "        'lambda_l1': trial.suggest_uniform('lambda_l1', 0.01, 4.0),\n",
    "        'lambda_l2': trial.suggest_uniform('lambda_l2', 0.01, 4.0),\n",
    "        'max_leaves': trial.suggest_int(\"max_leaves\", 15, 25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.3, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 1.0),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 3, 8),\n",
    "        'drop_rate': trial.suggest_uniform('drop_rate', 0.1, 0.3),\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "optimization_parameters = objective_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yspecies.workflow import SplitReduce\n",
    "\n",
    "def side(i: int):\n",
    "    print(i)\n",
    "    return i\n",
    "\n",
    "prepare_partition = SplitReduce(\n",
    "    outputs = DataPartitioner(), \n",
    "    split = lambda x: [(x[0], replace(partition_params, seed=side(x[2])))], \n",
    "    reduce = lambda x, output: (output[0], x[1]) \n",
    ")                               \n",
    "partition_and_cv = Pipeline(\n",
    "    [\n",
    "        (\"prepare partition\", prepare_partition),\n",
    "        ('crossvalidator', CrossValidator())\n",
    "    ]\n",
    ")\n",
    "\n",
    "partition_and_cv_repeat =  Pipeline([\n",
    "    (\"repeat_cv_pipe\", Repeat(partition_and_cv, repeats, \n",
    "                              lambda x, i: [x[0], x[1], i] )),\n",
    "    (\"collect_mean\", Collect(fold=lambda results: np.array([r.last(\"huber\") for r in results]).mean()))\n",
    "    ]\n",
    "    )\n",
    "\n",
    "p = Pipeline([\n",
    "     ('extractor', DataExtractor()),\n",
    "     ('tune', Tune(partition_and_cv_repeat, n_trials = 2, parameters_space = optimization_parameters))    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[200]\tcv_agg's l1: 1.73608 + 0.616772\tcv_agg's l2: 7.16199 + 5.39369\tcv_agg's huber: 1.22658 + 0.540433\n",
      "1\n",
      "[200]\tcv_agg's l1: 1.88651 + 0.26057\tcv_agg's l2: 14.8303 + 3.9075\tcv_agg's huber: 1.36376 + 0.214897\n",
      "2\n",
      "[200]\tcv_agg's l1: 1.82129 + 0.139542\tcv_agg's l2: 13.3656 + 1.89064\tcv_agg's huber: 1.30457 + 0.118265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:23:39,143] Trial 0 finished with value: 1.2983059083818629 and parameters: {'boosting_type': 'dart', 'lambda_l1': 1.5488814639964033, 'lambda_l2': 0.9436691893935235, 'max_leaves': 20, 'max_depth': 4, 'feature_fraction': 0.5361944688083496, 'bagging_fraction': 0.8645957050899689, 'learning_rate': 0.08851919639499403, 'min_data_in_leaf': 6, 'drop_rate': 0.2229770791364106}. Best is trial 0 with value: 1.2983059083818629.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\tcv_agg's l1: 0.091296 + 0.00948117\tcv_agg's l2: 0.0975205 + 0.0664387\tcv_agg's huber: 0.03581 + 0.0124123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tcv_agg's l1: 0.091296 + 0.00948117\tcv_agg's l2: 0.0975205 + 0.0664387\tcv_agg's huber: 0.03581 + 0.0124123\n",
      "1\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\tcv_agg's l1: 0.08863 + 0.0149316\tcv_agg's l2: 0.110497 + 0.0315277\tcv_agg's huber: 0.0428087 + 0.00756716\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tcv_agg's l1: 0.08863 + 0.0149316\tcv_agg's l2: 0.110497 + 0.0315277\tcv_agg's huber: 0.0428087 + 0.00756716\n",
      "2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[200]\tcv_agg's l1: 0.0975158 + 0.00530665\tcv_agg's l2: 0.23236 + 0.0499444\tcv_agg's huber: 0.0535257 + 0.00945229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tcv_agg's l1: 0.0975158 + 0.00530665\tcv_agg's l2: 0.23236 + 0.0499444\tcv_agg's huber: 0.0535257 + 0.00945229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:25:08,464] Trial 1 finished with value: 0.04404813160918101 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 3.5389955270605298, 'lambda_l2': 1.6581000555478702, 'max_leaves': 20, 'max_depth': 8, 'feature_fraction': 0.537151250668454, 'bagging_fraction': 0.6407512594833191, 'learning_rate': 0.06627424358150694, 'min_data_in_leaf': 3, 'drop_rate': 0.16918140176888039}. Best is trial 1 with value: 0.04404813160918101.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'lambda_l1': 3.5389955270605298,\n",
       " 'lambda_l2': 1.6581000555478702,\n",
       " 'max_leaves': 20,\n",
       " 'max_depth': 8,\n",
       " 'feature_fraction': 0.537151250668454,\n",
       " 'bagging_fraction': 0.6407512594833191,\n",
       " 'learning_rate': 0.06627424358150694,\n",
       " 'min_data_in_leaf': 3,\n",
       " 'drop_rate': 0.16918140176888039}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = p.fit_transform((data, select_lifespan))\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'lambda_l1': 3.5389955270605298,\n",
       " 'lambda_l2': 1.6581000555478702,\n",
       " 'max_leaves': 20,\n",
       " 'max_depth': 8,\n",
       " 'feature_fraction': 0.537151250668454,\n",
       " 'bagging_fraction': 0.6407512594833191,\n",
       " 'learning_rate': 0.06627424358150694,\n",
       " 'min_data_in_leaf': 3,\n",
       " 'drop_rate': 0.16918140176888039,\n",
       " 'metric': ['mae', 'mse', 'huber'],\n",
       " 'objective': 'regression'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best[\"metric\"] =  [\"mae\", \"mse\", \"huber\"]\n",
    "best['objective'] = 'regression'\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting shap results with the best parameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shap(params: dict):\n",
    "    partition_shap_pipe = Pipeline([\n",
    "        (\"partitioner\", DataPartitioner()),\n",
    "        ('prepare_for_partitioning', TupleWith(lgb_params)),\n",
    "        (\"shap_computation\", ShapSelector())\n",
    "    ]\n",
    "    )\n",
    "    repeated_cv =  Repeat(partition_shap_pipe, repeats, lambda x,i: (x[0], replace(x[1], seed = i)))\n",
    "    return Pipeline([\n",
    "        ('extractor', DataExtractor()),\n",
    "        ('prepare_for_partitioning', TupleWith(params)), # to extract the data required for ML from the dataset\n",
    "        (\"partition_shap\", repeated_cv)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() should be called on dataclass instances",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7f7a10e30cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp_shap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_shap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_shap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_lifespan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/yspecies/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m/opt/miniconda3/envs/yspecies/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/sources/yspecies/yspecies/workflow.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/sources/yspecies/yspecies/workflow.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-8a041169ccb3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, i)\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrepeated_cv\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mRepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_shap_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     return Pipeline([\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'extractor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/yspecies/lib/python3.8/dataclasses.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(*args, **changes)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_dataclass_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"replace() should be called on dataclass instances\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;31m# It's an error to have init=False fields in 'changes'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() should be called on dataclass instances"
     ]
    }
   ],
   "source": [
    "p_shap = make_shap(best)\n",
    "results = p_shap.fit_transform((data, select_lifespan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
